{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d854434",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0eb5899b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_pad_weights(weights):\n",
    "    i = 0\n",
    "    res = np.zeros(len(weights) + 7*len(weights)//9).flatten()\n",
    "\n",
    "    counter = 0\n",
    "    for w in weights:\n",
    "        # print(w)\n",
    "        if counter == 9:\n",
    "            i += 7\n",
    "            counter = 0\n",
    "        res[i] = w\n",
    "        counter += 1\n",
    "        i += 1\n",
    "\n",
    "    return res\n",
    "\n",
    "def zero_pad_layers(layers):\n",
    "    i = 0\n",
    "    res = np.zeros(len(layers) + 15*len(layers)).flatten()\n",
    "    print(len(layers)+4096*15)\n",
    "    counter = 0\n",
    "    for w in layers:\n",
    "        res[i*16] = w\n",
    "        i += 1\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ddcf51f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65536\n",
      "Block 8x8 loaded. Conv1: (256, 256, 3, 3), Conv2: (256, 256, 3, 3), float32\n",
      "Block 16x16 loaded. Conv1: (256, 256, 3, 3), Conv2: (256, 256, 3, 3), float32\n",
      "Block 32x32 loaded. Conv1: (256, 256, 3, 3), Conv2: (256, 256, 3, 3), float32\n",
      "Block 64x64 loaded. Conv1: (128, 256, 3, 3), Conv2: (128, 128, 3, 3), float32\n",
      "Block 128x128 loaded. Conv1: (64, 128, 3, 3), Conv2: (64, 64, 3, 3), float32\n",
      "Block 256x256 loaded. Conv1: (32, 64, 3, 3), Conv2: (32, 32, 3, 3), float32\n",
      "Block 512x512 loaded. Conv1: (16, 32, 3, 3), Conv2: (16, 16, 3, 3), float32\n",
      "Block 1024x1024 loaded. Conv1: (8, 16, 3, 3), Conv2: (8, 8, 3, 3), float32\n"
     ]
    }
   ],
   "source": [
    "\n",
    "CHECKPOINT_PATH = \"latest_checkpoint.pth\"\n",
    "\n",
    "q = 8\n",
    "scalse_factor = 2 ** q\n",
    "\n",
    "try:\n",
    "    checkpoint = torch.load(CHECKPOINT_PATH, map_location=\"cpu\")\n",
    "    gen_state = checkpoint[\"gen\"] if \"gen\" in checkpoint else checkpoint\n",
    "    # print(\"=> File berhasil dimuat.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"=> ERROR: File tidak ditemukan.\")\n",
    "    exit()\n",
    "\n",
    "def get_scaled_weight(tensor_weight):\n",
    "    w = tensor_weight\n",
    "    # Shape Conv: (Out, In, K, K)\n",
    "    # Fan In = In * K * K\n",
    "    fan_in = w.shape[1] * w.shape[2] * w.shape[3]\n",
    "    scale = np.sqrt(2 / fan_in)\n",
    "    return w * scale\n",
    "\n",
    "# Wadah untuk weight NumPy\n",
    "weights_numpy = {}\n",
    "\n",
    "# --- 1. EKSTRAKSI BLOK AWAL (4x4) ---\n",
    "# print(\"\\n--- Memuat Blok Awal (4x4) ---\")\n",
    "\n",
    "# Ambil Konstanta\n",
    "weights_numpy['const_input'] = ((gen_state[\"starting_constant\"].numpy())* scalse_factor).astype(np.int16)\n",
    "flat_weight = weights_numpy['const_input'].flatten()\n",
    "flat_weight = zero_pad_layers(flat_weight)\n",
    "flat_weight.tofile('weights_const_input.bin')\n",
    "# print(f\"[OK] Constant Input: {weights_numpy['const_input'].shape}\")\n",
    "\n",
    "# Ambil Konvolusi (Perhatikan key-nya!)\n",
    "weights_numpy['conv_4x4'] = (get_scaled_weight(gen_state[\"initial_conv.weight\"].numpy())* scalse_factor).astype(np.int16)\n",
    "weights_numpy['bias_4x4'] = (gen_state[\"initial_conv.bias\"].numpy() * scalse_factor).astype(np.int16)\n",
    "\n",
    "\n",
    "flat_weight = zero_pad_weights(weights_numpy['conv_4x4'].flatten())\n",
    "flat_weight.tofile('weights_conv_4x4.bin')\n",
    "\n",
    "flat_weight = weights_numpy['bias_4x4'].flatten()\n",
    "flat_weight.tofile('weights_bias_4x4.bin')\n",
    "# print(f\"[OK] Initial Conv: {weights_numpy['conv_4x4'].shape}\")\n",
    "\n",
    "# Ambil Noise\n",
    "weights_numpy['noise1_4x4'] = (gen_state[\"initial_noise1.weight\"].numpy() * scalse_factor).astype(np.int16)\n",
    "weights_numpy['noise2_4x4'] = (gen_state[\"initial_noise2.weight\"].numpy() * scalse_factor).astype(np.int16)\n",
    "\n",
    "flat_weight = weights_numpy['noise1_4x4'].flatten()\n",
    "flat_weight.tofile('weights_noise1_4x4.bin')\n",
    "flat_weight = weights_numpy['noise2_4x4'].flatten()\n",
    "flat_weight.tofile('weights_noise2_4x4.bin')\n",
    "\n",
    "# --- 2. EKSTRAKSI BLOK PROGRESIF (8x8 ke atas) ---\n",
    "# Gunakan logika loop seperti sebelumnya, tapi mulai dari index 0\n",
    "num_blocks = 0\n",
    "while f\"prog_blocks.{num_blocks}.conv1.conv.weight\" in gen_state:\n",
    "    num_blocks += 1\n",
    "\n",
    "# print(f\"\\n--- Memuat {num_blocks} Blok Progresif ---\")\n",
    "\n",
    "\n",
    "for i in range(num_blocks):\n",
    "    res = 4 * (2 ** (i + 1)) # 8, 16, 32...\n",
    "    \n",
    "    # Conv 1\n",
    "    k1 = (gen_state[f\"prog_blocks.{i}.conv1.conv.weight\"].numpy())\n",
    "    weights_numpy[f'conv1_{res}'] = (get_scaled_weight(k1)* scalse_factor).astype(np.int16)\n",
    "    fixed_weight = (weights_numpy[f'conv1_{res}'] )\n",
    "    flat_weight = fixed_weight.flatten()\n",
    "    flat_weight = zero_pad_weights(flat_weight)\n",
    "    flat_weight.tofile(f'weights_conv1_{res}.bin')\n",
    "    \n",
    "    # Conv 2\n",
    "    k2 = gen_state[f\"prog_blocks.{i}.conv2.conv.weight\"].numpy()\n",
    "    weights_numpy[f'conv2_{res}'] = (get_scaled_weight(k2)* scalse_factor).astype(np.int16)\n",
    "\n",
    "    fixed_weight = (weights_numpy[f'conv2_{res}'] )\n",
    "    flat_weight = fixed_weight.flatten()\n",
    "    flat_weight = zero_pad_weights(flat_weight)\n",
    "    flat_weight.tofile(f'weights_conv2_{res}.bin')\n",
    "    \n",
    "    # Noise\n",
    "    n1 = gen_state[f\"prog_blocks.{i}.inject_noise1.weight\"].numpy()\n",
    "    n2 = gen_state[f\"prog_blocks.{i}.inject_noise2.weight\"].numpy()\n",
    "    weights_numpy[f'noise1_{res}'] = (n1 * scalse_factor).astype(np.int16)\n",
    "    weights_numpy[f'noise2_{res}'] = (n2 * scalse_factor).astype(np.int16)\n",
    "\n",
    "    fixed_weight = (weights_numpy[f'noise1_{res}'])\n",
    "    flat_weight = fixed_weight.flatten()\n",
    "    flat_weight.tofile(f'weights_noise1_{res}.bin')\n",
    "\n",
    "    fixed_weight = (weights_numpy[f'noise2_{res}'])\n",
    "    flat_weight = fixed_weight.flatten()\n",
    "    flat_weight.tofile(f'weights_noise2_{res}.bin')\n",
    "\n",
    "    # bias\n",
    "    b1 = gen_state[f\"prog_blocks.{i}.conv1.bias\"].numpy()\n",
    "    b2 = gen_state[f\"prog_blocks.{i}.conv2.bias\"].numpy()\n",
    "    weights_numpy[f'bias1_{res}'] = (b1 * scalse_factor).astype(np.int16)\n",
    "    weights_numpy[f'bias2_{res}'] = (b2 * scalse_factor).astype(np.int16)\n",
    "\n",
    "    fixed_weight = (weights_numpy[f'bias1_{res}'])\n",
    "    flat_weight = fixed_weight.flatten()\n",
    "    flat_weight.tofile(f'weights_bias1_{res}.bin')\n",
    "\n",
    "    fixed_weight = (weights_numpy[f'bias2_{res}'])\n",
    "    flat_weight = fixed_weight.flatten()\n",
    "    flat_weight.tofile(f'weights_bias2_{res}.bin')\n",
    "    \n",
    "    print(f\"Block {res}x{res} loaded. Conv1: {k1.shape}, Conv2: {k2.shape}, {n1.dtype}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
